{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MoneyControl_Web_Scrapping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJZG0r5XKakK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0f762b-1b41-4960-d0d8-a3462f2606f8"
      },
      "source": [
        "!pip install requests #to generate http request\n",
        "!pip install beautifulsoup4 #to parse the data \n",
        "!pip install schedule #time scheduling "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n",
            "Collecting schedule\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/3b/040bd180eaef427dd160562ee66adc9f4f67088185c272edcdb899c609c7/schedule-1.1.0-py2.py3-none-any.whl\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6lR6RzeKop_"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import schedule\n",
        "from datetime import datetime, timezone\n",
        "import pytz"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxMqjH1zK2F2",
        "outputId": "7fa66b5e-db3f-4fbc-a60b-80a3c845412e"
      },
      "source": [
        "def job():\n",
        "    url=\"https://www.moneycontrol.com/news/business/stocks\"\n",
        "\n",
        "    # Make a GET request to fetch the raw HTML content\n",
        "    html_content = requests.get(url).text\n",
        "\n",
        "    # Parse the html content\n",
        "    soup = BeautifulSoup(html_content, \"lxml\")\n",
        "    # print(soup.prettify()) # print the parsed data of html\n",
        "\n",
        "    #get the required elements from the webpage\n",
        "    tble = soup.find('ul', {\"id\":\"cagetory\"})\n",
        "    tbleHeading = tble.find_all('h2')\n",
        "    tbleData = tble.find_all('p')\n",
        "\n",
        "    #saving the data in the form of a dict with key as heading and value as brief content\n",
        "    # print(len(tbleHeading), len(tbleData[::2]))\n",
        "    dataComplete = dict()\n",
        "    for i,j in zip(tbleHeading,tbleData[::2]):\n",
        "        dataComplete[i.text] = j.text\n",
        "\n",
        "    #converting the dict into a pandas dataframe\n",
        "    data = pd.DataFrame(data=dataComplete.items(),columns=[\"Heading\",\"content\"])\n",
        "\n",
        "    #saving the data to csv\n",
        "    IST = pytz.timezone('Asia/Kolkata')\n",
        "    datetime_ist = datetime.now(IST)\n",
        "    ts = datetime_ist.strftime('%H:%M:%S %d:%m:%Y')\n",
        "    print(ts)\n",
        "    data.to_csv('/content/test-'+ts+'.csv',index=False)\n",
        "\n",
        "schedule.every(4).hours.do(job)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Every 4 hours do job() (last run: [never], next run: 2021-04-30 09:26:03)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STlpqbcZjtBl"
      },
      "source": [
        "while True:\n",
        "    schedule.run_pending()\n",
        "    time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWhheNkGsQcv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9sM_T93jGNo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U-YOMwTI-mg"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbcJlL-TI-iH"
      },
      "source": [
        ""
      ]
    }
  ]
}